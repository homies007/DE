{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwziHn_au9zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53affabf-ddf0-42ca-9cde-553f10688bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: 2020-01-02\n",
            "Add 4 days: 2020-01-06\n",
            "Subtract 7 days: 2019-12-26\n",
            "--------------------\n",
            "Original: 2023-01-15\n",
            "Add 4 days: 2023-01-19\n",
            "Subtract 7 days: 2023-01-08\n",
            "--------------------\n",
            "Original: 2025-01-30\n",
            "Add 4 days: 2025-02-03\n",
            "Subtract 7 days: 2025-01-23\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "#1] Get new dates by adding 4 days, and subtracting 7 days in below dates\n",
        "#\"2020-01-02\",\"2023-01-15\",\"2025-01-30\"\n",
        "\n",
        "#Solution:\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Input dates\n",
        "dates = [\"2020-01-02\", \"2023-01-15\", \"2025-01-30\"]\n",
        "results = []\n",
        "\n",
        "# Process each date\n",
        "for date_str in dates:\n",
        "    # Convert string to datetime object\n",
        "    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "\n",
        "    # Add 4 days\n",
        "    add_4 = date_obj + timedelta(days=4)\n",
        "\n",
        "    # Subtract 7 days\n",
        "    sub_7 = date_obj - timedelta(days=7)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"original\": date_str,\n",
        "        \"add_4_days\": add_4.strftime(\"%Y-%m-%d\"),\n",
        "        \"sub_7_days\": sub_7.strftime(\"%Y-%m-%d\")\n",
        "    })\n",
        "\n",
        "# Print formatted output\n",
        "for res in results:\n",
        "    print(f\"Original: {res['original']}\")\n",
        "    print(f\"Add 4 days: {res['add_4_days']}\")\n",
        "    print(f\"Subtract 7 days: {res['sub_7_days']}\")\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2] Use the Operation Read CSV file on RDD with Scala operation\n",
        "\n",
        "#Solution:\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "# Correct Python/PySpark syntax\n",
        "conf = SparkConf().setAppName(\"CsvReader\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# Read CSV (PySpark example)\n",
        "csv_rdd = sc.textFile(\"input.csv\")\n",
        "header = csv_rdd.first()\n",
        "data_rdd = csv_rdd.filter(lambda line: line != header)\n",
        "\n",
        "# Parse (Python syntax)\n",
        "parsed_rdd = data_rdd.map(lambda line: line.split(\",\"))\n",
        "structured_rdd = parsed_rdd.map(lambda fields: (fields[0], int(fields[1]), float(fields[2])))\n",
        "\n",
        "# Verify\n",
        "print(\"Sample data:\")\n",
        "structured_rdd.take(5).foreach(print)\n",
        "\n",
        "sc.stop()\n"
      ],
      "metadata": {
        "id": "wJlWk1LsvJTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xCANmEZKjlM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}