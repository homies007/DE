{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4pv2tFnjN_x",
        "outputId": "6dd1a9a2-3dcd-44af-c62e-9e4d57d74e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "--- Initial DataFrame and Schema ---\n",
            "+--------------------+-----+------+--------+\n",
            "|                name|  dob|gender|expenses|\n",
            "+--------------------+-----+------+--------+\n",
            "|   {James;, , Smith}|36636|     M|   20000|\n",
            "|   {Michael, Rose, }|40288|     M|   40000|\n",
            "|{Robert, , Williams}|42114|     M|   10000|\n",
            "|{Maria, Anne, Jones}|39192|     F|   45000|\n",
            "|  {Jen, Mary, Brown}|     |     F|      -1|\n",
            "+--------------------+-----+------+--------+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- expenses: string (nullable = true)\n",
            "\n",
            "\n",
            "--- Final DataFrame and Schema after Operations ---\n",
            "+--------------------+-----------+------+--------+------------------+\n",
            "|name                |DateOfBirth|gender|expenses|expense_multiplied|\n",
            "+--------------------+-----------+------+--------+------------------+\n",
            "|{James;, , Smith}   |36636      |M     |20000   |100000            |\n",
            "|{Michael, Rose, }   |40288      |M     |40000   |200000            |\n",
            "|{Robert, , Williams}|42114      |M     |10000   |50000             |\n",
            "|{Maria, Anne, Jones}|39192      |F     |45000   |225000            |\n",
            "|{Jen, Mary, Brown}  |           |F     |-1      |-5                |\n",
            "+--------------------+-----------+------+--------+------------------+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- DateOfBirth: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- expenses: integer (nullable = true)\n",
            " |-- expense_multiplied: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1] For the following data and schema create a dataframe and perform the given operations\n",
        "#Perform the following operations:\n",
        "#a) Change the data type of expenses to Integer\n",
        "#b) Rename dob to DateOfBirth\n",
        "#c) Create a column that has value expense*5\n",
        "\n",
        "#Solution:\n",
        "\n",
        "# Install PySpark\n",
        "!pip install pyspark\n",
        "\n",
        "# Import necessary classes and functions\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"DataFrameOperations\").getOrCreate()\n",
        "\n",
        "# Define the nested schema\n",
        "schema = StructType([\n",
        "    StructField('name', StructType([\n",
        "         StructField('firstname', StringType(), True),\n",
        "         StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "         ])),\n",
        "     StructField('dob', StringType(), True),\n",
        "     StructField('gender', StringType(), True),\n",
        "     StructField('expenses', StringType(), True)\n",
        "])\n",
        "\n",
        "# Prepare the data\n",
        "# Note: The semicolon in \"James;\" is included as per the provided data\n",
        "data = [\n",
        "    Row(name=Row(\"James;\", \"\", \"Smith\"), dob=\"36636\", gender=\"M\", expenses=\"20000\"),\n",
        "    Row(name=Row(\"Michael\", \"Rose\", \"\"), dob=\"40288\", gender=\"M\", expenses=\"40000\"),\n",
        "    Row(name=Row(\"Robert\", \"\", \"Williams\"), dob=\"42114\", gender=\"M\", expenses=\"10000\"),\n",
        "    Row(name=Row(\"Maria\", \"Anne\", \"Jones\"), dob=\"39192\", gender=\"F\", expenses=\"45000\"),\n",
        "    Row(name=Row(\"Jen\", \"Mary\", \"Brown\"), dob=\"\", gender=\"F\", expenses=\"-1\")\n",
        "]\n",
        "\n",
        "# Create the DataFrame\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "print(\"--- Initial DataFrame and Schema ---\")\n",
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "# Perform all transformations\n",
        "final_df = df.withColumn(\"expenses\", col(\"expenses\").cast(IntegerType())) \\\n",
        "             .withColumnRenamed(\"dob\", \"DateOfBirth\") \\\n",
        "             .withColumn(\"expense_multiplied\", col(\"expenses\") * 5)\n",
        "\n",
        "print(\"\\n--- Final DataFrame and Schema after Operations ---\")\n",
        "final_df.show(truncate=False)\n",
        "final_df.printSchema()\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2] Create a data frame with a nested array column. Perform the following operations:\n",
        "#a) Flatten nested array\n",
        "#b) Explode nested array\n",
        "#c) Convert array of string to string column.\n",
        "\n",
        "#Solution:\n",
        "\n",
        "# Install PySpark\n",
        "!pip install pyspark\n",
        "\n",
        "# Import necessary functions and types\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, flatten, explode, concat_ws\n",
        "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"NestedArrayOperations\").getOrCreate()\n",
        "\n",
        "# Define data with a nested array [[\"subject\", \"score\"], ...]\n",
        "data = [\n",
        "    (\"Alice\", [[\"Math\", \"90\"], [\"Science\", \"85\"]]),\n",
        "    (\"Bob\", [[\"History\", \"88\"], [\"English\", \"92\"]]),\n",
        "    (\"Charlie\", [[\"Art\", \"95\"]])\n",
        "]\n",
        "\n",
        "# Define the schema for the nested array\n",
        "schema = StructType([\n",
        "    StructField(\"name\", StringType()),\n",
        "    StructField(\"subjects\", ArrayType(ArrayType(StringType())))\n",
        "])\n",
        "\n",
        "# Create the DataFrame\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "print(\"--- Initial DataFrame with Nested Array ---\")\n",
        "df.show(truncate=False)\n",
        "df.printSchema()\n",
        "\n",
        "# Flatten the 'subjects' column\n",
        "flattened_df = df.withColumn(\"flat_subjects\", flatten(col(\"subjects\")))\n",
        "\n",
        "print(\"--- a) DataFrame with Flattened Array ---\")\n",
        "flattened_df.show(truncate=False)\n",
        "flattened_df.printSchema()\n",
        "\n",
        "# Explode the 'subjects' column\n",
        "exploded_df = df.withColumn(\"exploded_subjects\", explode(col(\"subjects\")))\n",
        "\n",
        "print(\"--- b) DataFrame with Exploded Array ---\")\n",
        "exploded_df.show(truncate=False)\n",
        "exploded_df.printSchema()\n",
        "\n",
        "# First, flatten the array (using the DataFrame from step a)\n",
        "# Then, convert the flattened array into a comma-separated string\n",
        "string_df = flattened_df.withColumn(\n",
        "    \"subjects_string\",\n",
        "    concat_ws(\", \", col(\"flat_subjects\"))\n",
        ")\n",
        "\n",
        "print(\"--- c) DataFrame with Array Converted to String ---\")\n",
        "string_df.show(truncate=False)\n",
        "string_df.printSchema()\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to1Jk5bDkA43",
        "outputId": "4ba56191-654d-475a-f780-201cbc355044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "--- Initial DataFrame with Nested Array ---\n",
            "+-------+------------------------------+\n",
            "|name   |subjects                      |\n",
            "+-------+------------------------------+\n",
            "|Alice  |[[Math, 90], [Science, 85]]   |\n",
            "|Bob    |[[History, 88], [English, 92]]|\n",
            "|Charlie|[[Art, 95]]                   |\n",
            "+-------+------------------------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjects: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            "\n",
            "--- a) DataFrame with Flattened Array ---\n",
            "+-------+------------------------------+--------------------------+\n",
            "|name   |subjects                      |flat_subjects             |\n",
            "+-------+------------------------------+--------------------------+\n",
            "|Alice  |[[Math, 90], [Science, 85]]   |[Math, 90, Science, 85]   |\n",
            "|Bob    |[[History, 88], [English, 92]]|[History, 88, English, 92]|\n",
            "|Charlie|[[Art, 95]]                   |[Art, 95]                 |\n",
            "+-------+------------------------------+--------------------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjects: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- flat_subjects: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "--- b) DataFrame with Exploded Array ---\n",
            "+-------+------------------------------+-----------------+\n",
            "|name   |subjects                      |exploded_subjects|\n",
            "+-------+------------------------------+-----------------+\n",
            "|Alice  |[[Math, 90], [Science, 85]]   |[Math, 90]       |\n",
            "|Alice  |[[Math, 90], [Science, 85]]   |[Science, 85]    |\n",
            "|Bob    |[[History, 88], [English, 92]]|[History, 88]    |\n",
            "|Bob    |[[History, 88], [English, 92]]|[English, 92]    |\n",
            "|Charlie|[[Art, 95]]                   |[Art, 95]        |\n",
            "+-------+------------------------------+-----------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjects: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- exploded_subjects: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "--- c) DataFrame with Array Converted to String ---\n",
            "+-------+------------------------------+--------------------------+------------------------+\n",
            "|name   |subjects                      |flat_subjects             |subjects_string         |\n",
            "+-------+------------------------------+--------------------------+------------------------+\n",
            "|Alice  |[[Math, 90], [Science, 85]]   |[Math, 90, Science, 85]   |Math, 90, Science, 85   |\n",
            "|Bob    |[[History, 88], [English, 92]]|[History, 88, English, 92]|History, 88, English, 92|\n",
            "|Charlie|[[Art, 95]]                   |[Art, 95]                 |Art, 95                 |\n",
            "+-------+------------------------------+--------------------------+------------------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjects: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- flat_subjects: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- subjects_string: string (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9yEZUrG9k4KC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}